#!/usr/bin/env python3
"""
è¯¦ç»†åˆ†æéå‡è¡¡ç»“æ„åŒ–å‰ªæè¿‡ç¨‹
å±•ç¤ºæ­¥éª¤3ï¼ˆåˆ›å»ºæ¨¡å—çº§å‰ªæç‡å­—å…¸ï¼‰å’Œæ­¥éª¤4ï¼ˆç»“æ„åŒ–å‰ªæï¼‰çš„ç»†èŠ‚
"""

import torch
import json
from transformers import AutoModelForCausalLM, AutoTokenizer
from typing import Dict


def load_pruning_config(config_path: str) -> Dict:
    """åŠ è½½å‰ªæé…ç½®"""
    with open(config_path, 'r') as f:
        config = json.load(f)
    return config['layer_pruning_rates']


def analyze_layer_filtering(layer_pruning_rates: Dict[int, float],
                            block_attention_start: int = 3,
                            block_attention_end: int = 30,
                            block_mlp_start: int = 3,
                            block_mlp_end: int = 30):
    """
    åˆ†ææ­¥éª¤3ï¼šå±‚è¿‡æ»¤é€»è¾‘

    è§£é‡Šä¸ºä»€ä¹ˆè™½ç„¶è®¡ç®—äº†æ‰€æœ‰å±‚ï¼ˆ0-31ï¼‰çš„å‰ªæç‡ï¼Œ
    ä½†å®é™…åªå‰ªæ3-29å±‚
    """
    print("=" * 80)
    print("æ­¥éª¤3è¯¦è§£ï¼šå±‚è¿‡æ»¤å’Œæ¨¡å—çº§å‰ªæç‡å­—å…¸åˆ›å»º")
    print("=" * 80)
    print()

    # 1. æ˜¾ç¤ºæ‰€æœ‰å±‚çš„è®¡ç®—ç»“æœ
    print("1ï¸âƒ£  æ‰€æœ‰å±‚çš„å‰ªæç‡ï¼ˆæ­¥éª¤2è®¡ç®—ç»“æœï¼‰:")
    print("-" * 80)
    for layer_idx in sorted(layer_pruning_rates.keys()):
        rate = layer_pruning_rates[layer_idx]
        print(f"   Layer {layer_idx:2d}: {rate:.4f}")
    print()

    # 2. æ˜¾ç¤ºè¿‡æ»¤é€»è¾‘
    print("2ï¸âƒ£  å±‚è¿‡æ»¤é€»è¾‘ï¼ˆä»£ç ç¬¬222-228è¡Œï¼‰:")
    print("-" * 80)
    print(f"   å‚æ•°é…ç½®:")
    print(f"     --block_attention_layer_start = {block_attention_start}")
    print(f"     --block_attention_layer_end   = {block_attention_end}")
    print(f"     --block_mlp_layer_start       = {block_mlp_start}")
    print(f"     --block_mlp_layer_end         = {block_mlp_end}")
    print()
    print(f"   Python range() è§„åˆ™:")
    print(f"     range({block_attention_start}, {block_attention_end}) = [{block_attention_start}, {block_attention_start+1}, ..., {block_attention_end-1}]  (ä¸åŒ…å«{block_attention_end})")
    print()

    # 3. æ˜¾ç¤ºè¿‡æ»¤ç»“æœ
    pruning_layers = set(range(block_attention_start, block_attention_end)) | \
                     set(range(block_mlp_start, block_mlp_end))

    filtered_rates = {
        idx: rate for idx, rate in layer_pruning_rates.items()
        if idx in pruning_layers
    }

    print("3ï¸âƒ£  è¿‡æ»¤åå®é™…å‚ä¸å‰ªæçš„å±‚:")
    print("-" * 80)
    print(f"   å®é™…å‰ªæå±‚é›†åˆ: {sorted(pruning_layers)}")
    print(f"   å…± {len(pruning_layers)} å±‚")
    print()

    # 4. æ˜¾ç¤ºè¢«ä¿æŠ¤çš„å±‚
    all_layers = set(layer_pruning_rates.keys())
    protected_layers = all_layers - pruning_layers

    print("4ï¸âƒ£  è¢«ä¿æŠ¤ï¼ˆä¸å‰ªæï¼‰çš„å±‚:")
    print("-" * 80)
    print(f"   ä¸å‰ªæå±‚é›†åˆ: {sorted(protected_layers)}")
    print()
    print("   ğŸ›¡ï¸  ä¿æŠ¤åŸå› :")
    early_layers = [i for i in protected_layers if i < block_attention_start]
    late_layers = [i for i in protected_layers if i >= block_attention_end]

    if early_layers:
        print(f"     - å‰ {len(early_layers)} å±‚ {early_layers}: åº•å±‚ç‰¹å¾æå–å±‚ï¼Œå¯¹æ¨¡å‹æ€§èƒ½å½±å“å¤§")
    if late_layers:
        print(f"     - å {len(late_layers)} å±‚ {late_layers}: é«˜å±‚è¯­ä¹‰ç†è§£å±‚ï¼Œå¯¹æ¨¡å‹æ€§èƒ½å½±å“å¤§")
    print()

    return filtered_rates, pruning_layers


def analyze_ch_sparsity_dict_creation(model, filtered_rates: Dict[int, float],
                                      prune_attention: bool = True,
                                      prune_mlp: bool = True):
    """
    åˆ†æ ch_sparsity_dict çš„åˆ›å»ºè¿‡ç¨‹
    """
    print("=" * 80)
    print("æ­¥éª¤3è¯¦è§£ï¼šch_sparsity_dictï¼ˆæ¨¡å—çº§å‰ªæç‡å­—å…¸ï¼‰åˆ›å»º")
    print("=" * 80)
    print()

    print("5ï¸âƒ£  ch_sparsity_dict æ˜¯ä»€ä¹ˆï¼Ÿ")
    print("-" * 80)
    print("   ch_sparsity_dict æ˜¯ä¸€ä¸ª Python å­—å…¸ï¼Œå°† PyTorch æ¨¡å—å¯¹è±¡æ˜ å°„åˆ°å…¶å‰ªæç‡")
    print("   æ ¼å¼: {module_object: pruning_rate}")
    print()
    print("   ä½œç”¨: å‘Šè¯‰ MetaPruner æ¯ä¸ªæ¨¡å—åº”è¯¥å‰ªæå¤šå°‘æ¯”ä¾‹çš„é€šé“æ•°")
    print()

    print("6ï¸âƒ£  ä¸ºä»€ä¹ˆé€‰æ‹© k_proj å’Œ gate_proj ä½œä¸º root modulesï¼Ÿ")
    print("-" * 80)
    print("   Llama æ¨¡å‹æ¶æ„:")
    print("     æ¯å±‚åŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶:")
    print("       1. Self-Attention: q_proj, k_proj, v_proj, o_proj")
    print("       2. MLP:           gate_proj, up_proj, down_proj")
    print()
    print("   ç»“æ„åŒ–å‰ªæè§„åˆ™:")
    print("     - Attention: å‰ªæ k_proj çš„è¾“å‡ºé€šé“ â†’ è‡ªåŠ¨ä¼ æ’­åˆ° q_proj, v_proj, o_proj")
    print("     - MLP:       å‰ªæ gate_proj çš„è¾“å‡ºé€šé“ â†’ è‡ªåŠ¨ä¼ æ’­åˆ° up_proj, down_proj")
    print()
    print("   è¿™æ ·åªéœ€è®¾ç½® 2 ä¸ª root moduleï¼Œå°±èƒ½å‰ªææ•´å±‚çš„ 7 ä¸ªçº¿æ€§å±‚ï¼")
    print()

    # åˆ›å»º ch_sparsity_dict
    ch_sparsity_dict = {}

    print("7ï¸âƒ£  ch_sparsity_dict å†…å®¹ï¼ˆlayer_importance.py:312-327ï¼‰:")
    print("-" * 80)

    layer_module_info = []

    for layer_idx, pruning_rate in sorted(filtered_rates.items()):
        layer = model.model.layers[layer_idx]

        modules_in_layer = []

        # Attention
        if prune_attention and hasattr(layer, 'self_attn'):
            k_proj = layer.self_attn.k_proj
            ch_sparsity_dict[k_proj] = pruning_rate
            modules_in_layer.append(('k_proj', k_proj, pruning_rate))

        # MLP
        if prune_mlp and hasattr(layer, 'mlp'):
            gate_proj = layer.mlp.gate_proj
            ch_sparsity_dict[gate_proj] = pruning_rate
            modules_in_layer.append(('gate_proj', gate_proj, pruning_rate))

        layer_module_info.append((layer_idx, modules_in_layer))

    # æ˜¾ç¤ºå‰3å±‚å’Œå3å±‚ä½œä¸ºç¤ºä¾‹
    print("   ç¤ºä¾‹ï¼ˆå‰3å±‚ï¼‰:")
    for layer_idx, modules in layer_module_info[:3]:
        print(f"\n   Layer {layer_idx} (å‰ªæç‡: {filtered_rates[layer_idx]:.4f}):")
        for mod_name, mod_obj, rate in modules:
            print(f"     - {mod_name}: {type(mod_obj).__name__} â†’ å‰ªæç‡ {rate:.4f}")
            print(f"       å†…å­˜åœ°å€: {hex(id(mod_obj))}")

    print("\n   ...")

    print("\n   ç¤ºä¾‹ï¼ˆå3å±‚ï¼‰:")
    for layer_idx, modules in layer_module_info[-3:]:
        print(f"\n   Layer {layer_idx} (å‰ªæç‡: {filtered_rates[layer_idx]:.4f}):")
        for mod_name, mod_obj, rate in modules:
            print(f"     - {mod_name}: {type(mod_obj).__name__} â†’ å‰ªæç‡ {rate:.4f}")
            print(f"       å†…å­˜åœ°å€: {hex(id(mod_obj))}")

    print()
    print(f"   æ€»è®¡: {len(ch_sparsity_dict)} ä¸ªæ¨¡å—è®¾ç½®äº†è‡ªå®šä¹‰å‰ªæç‡")
    print(f"   è®¡ç®—: {len(filtered_rates)} å±‚ Ã— 2 æ¨¡å—/å±‚ = {len(filtered_rates) * 2} ä¸ªæ¨¡å—")
    print()

    return ch_sparsity_dict


def explain_metapruner_workflow(ch_sparsity_dict):
    """
    è§£é‡Šæ­¥éª¤4ï¼šMetaPruner çš„å·¥ä½œæµç¨‹
    """
    print("=" * 80)
    print("æ­¥éª¤4è¯¦è§£ï¼šMetaPruner ç»“æ„åŒ–å‰ªæå·¥ä½œæµç¨‹")
    print("=" * 80)
    print()

    print("8ï¸âƒ£  ä»€ä¹ˆæ˜¯ç»“æ„åŒ–å‰ªæï¼Ÿ")
    print("-" * 80)
    print("   éç»“æ„åŒ–å‰ªæï¼ˆç¨€ç–å‰ªæï¼‰:")
    print("     - å°†æƒé‡çŸ©é˜µä¸­çš„æŸäº›å…ƒç´ è®¾ä¸º 0")
    print("     - å‚æ•°é€»è¾‘ä¸Šå‡å°‘ï¼Œä½†ç‰©ç†å†…å­˜ä¸å‡å°‘")
    print("     - éœ€è¦ç¨€ç–çŸ©é˜µè¿ç®—æ”¯æŒæ‰èƒ½åŠ é€Ÿ")
    print()
    print("   ç»“æ„åŒ–å‰ªæï¼ˆé€šé“å‰ªæï¼‰:")
    print("     - åˆ é™¤æ•´ä¸ªé€šé“ï¼ˆç¥ç»å…ƒï¼‰")
    print("     - ç‰©ç†ä¸Šå‡å°æ¨¡å‹å°ºå¯¸")
    print("     - ç›´æ¥åŠ é€Ÿï¼Œæ— éœ€ç‰¹æ®Šç¡¬ä»¶æ”¯æŒ")
    print()
    print("   ç¤ºä¾‹:")
    print("     åŸå§‹: Linear(4096 â†’ 4096)")
    print("     å‰ªæ 25%: Linear(4096 â†’ 3072)  âœ… çœŸæ­£å‡å°‘å‚æ•°å’Œæ˜¾å­˜")
    print()

    print("9ï¸âƒ£  MetaPruner æ˜¯ä»€ä¹ˆï¼Ÿ")
    print("-" * 80)
    print("   MetaPruner æ˜¯ Torch-Pruning åº“çš„æ ¸å¿ƒå‰ªæå™¨")
    print("   ç‰¹ç‚¹:")
    print("     1. è‡ªåŠ¨è¿½è¸ªæ¨¡å—ä¹‹é—´çš„ä¾èµ–å…³ç³»")
    print("     2. ç¡®ä¿å‰ªæåæ¨¡å‹ç»“æ„ä¸€è‡´æ€§")
    print("     3. æ”¯æŒå„ç§é‡è¦æ€§è¯„ä¼°æ–¹æ³•ï¼ˆTaylorã€L1ã€L2ç­‰ï¼‰")
    print()

    print("ğŸ”Ÿ  MetaPruner å·¥ä½œæµç¨‹:")
    print("-" * 80)
    print()
    print("   ç¬¬1æ­¥: æ„å»ºä¾èµ–å›¾ï¼ˆDependency Graphï¼‰")
    print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("     è¾“å…¥: forward_promptsï¼ˆç¤ºä¾‹è¾“å…¥å¼ é‡ï¼‰")
    print("     è¿‡ç¨‹: æ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œè®°å½•æ‰€æœ‰æ¨¡å—çš„è¾“å…¥è¾“å‡ºå…³ç³»")
    print("     è¾“å‡º: ä¾èµ–å›¾ï¼Œè®°å½•å“ªäº›æ¨¡å—çš„è¾“å‡ºè¿æ¥åˆ°å“ªäº›æ¨¡å—çš„è¾“å…¥")
    print()
    print("     ç¤ºä¾‹:")
    print("       Layer 3:")
    print("         k_proj (4096â†’1024) â†’ RMSNorm â†’ Attention")
    print("                 â†“")
    print("         q_proj (4096â†’4096) â”€â”€â”˜")
    print("         v_proj (4096â†’1024) â”€â”€â”˜")
    print("                 â†“")
    print("         o_proj (4096â†’4096)")
    print()

    print("   ç¬¬2æ­¥: è®¡ç®—é€šé“é‡è¦æ€§")
    print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("     å¯¹äºæ¯ä¸ªè¦å‰ªæçš„æ¨¡å—:")
    print("       - Taylor é‡è¦æ€§: importance = |âˆ‚L/âˆ‚W Ã— W|")
    print("       - L1 é‡è¦æ€§:     importance = |W|")
    print("       - L2 é‡è¦æ€§:     importance = ||W||â‚‚")
    print()
    print("     ä¸ºæ¯ä¸ªè¾“å‡ºé€šé“è®¡ç®—é‡è¦æ€§åˆ†æ•°")
    print()

    print("   ç¬¬3æ­¥: é€‰æ‹©è¦å‰ªæçš„é€šé“")
    print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("     å¯¹äºæ¯ä¸ªæ¨¡å— (æ ¹æ® ch_sparsity_dict):")
    print()
    print("       ä¾‹å¦‚: Layer 5 çš„ k_proj, å‰ªæç‡ = 0.2629")
    print()
    print("         åŸå§‹é€šé“æ•°: 1024")
    print("         ä¿ç•™é€šé“æ•°: 1024 Ã— (1 - 0.2629) = 755")
    print("         å‰ªæé€šé“æ•°: 1024 - 755 = 269")
    print()
    print("         é€‰æ‹©é‡è¦æ€§æœ€ä½çš„ 269 ä¸ªé€šé“è¿›è¡Œå‰ªæ")
    print()

    print("   ç¬¬4æ­¥: ä¼ æ’­å‰ªæå†³ç­–")
    print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("     æ ¹æ®ä¾èµ–å›¾ï¼Œè‡ªåŠ¨ä¼ æ’­å‰ªæ:")
    print()
    print("       Layer 5 ç¤ºä¾‹:")
    print("         k_proj è¾“å‡º: 1024 â†’ 755 é€šé“")
    print("           â†“ (ä¾èµ–å…³ç³»è‡ªåŠ¨ä¼ æ’­)")
    print("         q_proj è¾“å‡º: 4096 â†’ 3020 é€šé“  (åŒæ¯”ä¾‹)")
    print("         v_proj è¾“å‡º: 1024 â†’ 755 é€šé“")
    print("         o_proj è¾“å…¥: 4096 â†’ 3020 é€šé“")
    print()
    print("       è¿™ä¿è¯äº† Attention æœºåˆ¶çš„ä¸€è‡´æ€§ï¼")
    print()

    print("   ç¬¬5æ­¥: ç‰©ç†æ‰§è¡Œå‰ªæ")
    print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("     å¯¹äºæ¯ä¸ªè¢«æ ‡è®°å‰ªæçš„é€šé“:")
    print("       1. ä»æƒé‡çŸ©é˜µä¸­åˆ é™¤å¯¹åº”çš„è¡Œ/åˆ—")
    print("       2. æ›´æ–°æ¨¡å—çš„ in_features å’Œ out_features")
    print("       3. é‡Šæ”¾æ˜¾å­˜")
    print()
    print("     ç¤ºä¾‹:")
    print("       åŸå§‹: k_proj = Linear(in=4096, out=1024)")
    print("         weight.shape = [1024, 4096]")
    print("         å‚æ•°é‡ = 4,194,304")
    print()
    print("       å‰ªæå: k_proj = Linear(in=4096, out=755)")
    print("         weight.shape = [755, 4096]")
    print("         å‚æ•°é‡ = 3,092,480")
    print("         å‡å°‘ = 1,101,824 (26.29%)")
    print()

    print("1ï¸âƒ£1ï¸âƒ£  è¿­ä»£å¼å‰ªæï¼ˆIterative Pruningï¼‰")
    print("-" * 80)
    print("   ä¸ºä»€ä¹ˆéœ€è¦å¤šæ¬¡è¿­ä»£ï¼Ÿ")
    print("     - ä¸€æ¬¡æ€§å¤§å¹…å‰ªæä¼šä¸¥é‡æŸå®³æ¨¡å‹æ€§èƒ½")
    print("     - é€æ­¥å‰ªæå…è®¸æ¨¡å‹åœ¨æ¯æ­¥åé€‚åº”")
    print()
    print("   ç¤ºä¾‹ï¼ˆ3æ¬¡è¿­ä»£ï¼Œç›®æ ‡å‰ªæç‡25%ï¼‰:")
    print("     è¿­ä»£ 1: å‰ªæ 8.33%")
    print("     è¿­ä»£ 2: å‰ªæ 8.33%")
    print("     è¿­ä»£ 3: å‰ªæ 8.34%")
    print("     æ€»è®¡:   25%")
    print()

    print("1ï¸âƒ£2ï¸âƒ£  ä¸ºä»€ä¹ˆæ—¥å¿—æ˜¾ç¤º 3-29 å±‚ï¼Ÿ")
    print("-" * 80)
    print("   åŸå› æ€»ç»“:")
    print("     âœ… æ­¥éª¤2 è®¡ç®—äº†æ‰€æœ‰å±‚ï¼ˆ0-31ï¼‰çš„å‰ªæç‡")
    print("     âœ… æ­¥éª¤3 æ ¹æ®å‚æ•°è¿‡æ»¤ï¼Œåªä¿ç•™ 3-29 å±‚")
    print("     âœ… æ­¥éª¤4 åªå¯¹è¿‡æ»¤åçš„å±‚æ‰§è¡Œå®é™…å‰ªæ")
    print()
    print("   å¥½å¤„:")
    print("     ğŸ›¡ï¸  ä¿æŠ¤å…³é”®å±‚ï¼ˆå‰3å±‚å’Œå2å±‚ï¼‰")
    print("     ğŸ“Š ä¿æŒæ›´å¥½çš„æ€§èƒ½ï¼ˆPPL æ›´ä½ï¼‰")
    print("     âš–ï¸  åœ¨å‰ªæç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—å¹³è¡¡")
    print()


def main():
    import argparse
    parser = argparse.ArgumentParser(description='åˆ†æéå‡è¡¡ç»“æ„åŒ–å‰ªæçš„è¯¦ç»†è¿‡ç¨‹')
    parser.add_argument('--config', type=str,
                       default='prune_log/llama_unbalanced_prune/layer_importance_config.json',
                       help='å±‚é‡è¦æ€§é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model', type=str,
                       default='/mnt/sharedata/song/models/Meta-Llama-3-8B-Instruct',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--block_attention_layer_start', type=int, default=3)
    parser.add_argument('--block_attention_layer_end', type=int, default=30)
    parser.add_argument('--block_mlp_layer_start', type=int, default=3)
    parser.add_argument('--block_mlp_layer_end', type=int, default=30)

    args = parser.parse_args()

    print()
    print("ğŸ” éå‡è¡¡ç»“æ„åŒ–å‰ªæè¯¦ç»†åˆ†æ")
    print("=" * 80)
    print()

    # åŠ è½½é…ç½®
    print("åŠ è½½å‰ªæé…ç½®...")
    layer_pruning_rates = load_pruning_config(args.config)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(layer_pruning_rates)} å±‚çš„å‰ªæç‡é…ç½®")
    print()

    # åˆ†æå±‚è¿‡æ»¤
    filtered_rates, pruning_layers = analyze_layer_filtering(
        layer_pruning_rates,
        args.block_attention_layer_start,
        args.block_attention_layer_end,
        args.block_mlp_layer_start,
        args.block_mlp_layer_end
    )

    # åŠ è½½æ¨¡å‹ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼Œä¸æ‰§è¡Œå®é™…å‰ªæï¼‰
    print("åŠ è½½æ¨¡å‹ç»“æ„ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰...")
    try:
        model = AutoModelForCausalLM.from_pretrained(
            args.model,
            device_map='cpu',
            torch_dtype=torch.float16,
            low_cpu_mem_usage=True
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print()

        # åˆ†æ ch_sparsity_dict åˆ›å»º
        ch_sparsity_dict = analyze_ch_sparsity_dict_creation(
            model, filtered_rates,
            prune_attention=True,
            prune_mlp=True
        )

    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("ç»§ç»­è¿›è¡ŒåŸç†è®²è§£...")
        print()
        ch_sparsity_dict = None

    # è§£é‡Š MetaPruner å·¥ä½œæµç¨‹
    explain_metapruner_workflow(ch_sparsity_dict)

    print("=" * 80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("=" * 80)
    print()
    print("æ€»ç»“:")
    print("  1. æ­¥éª¤2 è®¡ç®—æ‰€æœ‰å±‚çš„å‰ªæç‡ï¼ˆåŸºäºå±‚é‡è¦æ€§ï¼‰")
    print("  2. æ­¥éª¤3 è¿‡æ»¤å±‚ + åˆ›å»ºæ¨¡å—çº§å­—å…¸ï¼ˆä¿æŠ¤å…³é”®å±‚ï¼‰")
    print("  3. æ­¥éª¤4 MetaPruner æ‰§è¡Œç»“æ„åŒ–å‰ªæï¼ˆç‰©ç†å‡å°æ¨¡å‹ï¼‰")
    print()
    print("è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ:")
    print("  ğŸ“Š çœ‹åˆ° 32 å±‚çš„å‰ªæç‡")
    print("  âœ‚ï¸  ä½†åªå‰ªæ 27 å±‚ï¼ˆ3-29ï¼‰")
    print()


if __name__ == '__main__':
    main()
