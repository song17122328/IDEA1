cd /data/home/yuanxiaosong/LLM-Pruner/
git pull origin claude/fix-tuple-grad-fn-error-011CUywXCqgkBWjHYGzNQQJN

# 清除缓存
find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null
find . -name "*.pyc" -delete

# 重新运行（现在日志会是中文）
python llama3.py --pruning_ratio 0.25 \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --block_wise \
    --block_mlp_layer_start 3 --block_mlp_layer_end 30 \
    --block_attention_layer_start 3 --block_attention_layer_end 30 \
    --pruner_type taylor \
    --save_model

# 检查模型大小
python check_model_size.py

# 步骤 2：运行分析
python analyze_pruning.py \
    --original_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruned_model prune_log/llama_prune/pytorch_model.bin \
    --output llama3_pruning_analysis.csv


# 运行非均衡剪枝
python llama3_unbalanced_pruning.py \
    --base_model /newdata/LLMs/Llama-3-8B-Instruct \
    --pruning_ratio 0.25 \
    --importance_method removal \
    --importance_samples 50 \
    --pruning_strategy inverse \
    --alpha 1.5 \
    --save_model \
    --test_after_train