#!/usr/bin/env python3
"""
å‰ªæåˆ†æå·¥å…·
è¯¦ç»†åˆ†æåŸå§‹æ¨¡å‹å’Œå‰ªæåæ¨¡å‹çš„æ¯ä¸€å±‚å‚æ•°ç»´åº¦ã€å‰ªæåº¦å’Œç»“æ„åŒ–ç¨€ç–åº¦
"""

import torch
import argparse
from pathlib import Path
from collections import defaultdict
import pandas as pd


def load_model(model_path, is_pruned=False):
    """åŠ è½½æ¨¡å‹"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")

    if is_pruned:
        # å‰ªæåçš„æ¨¡å‹ä¿å­˜æ ¼å¼
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        if 'model' in checkpoint:
            model = checkpoint['model']
        else:
            model = checkpoint
    else:
        # åŸå§‹ HuggingFace æ¨¡å‹
        from transformers import LlamaForCausalLM
        model = LlamaForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            device_map='cpu'
        )

    return model


def analyze_layer(layer, layer_idx, model_type="original"):
    """åˆ†æå•ä¸ª transformer å±‚çš„å‚æ•°"""
    stats = {
        'layer_idx': layer_idx,
        'model_type': model_type,
    }

    # Attention æ¨¡å—
    if hasattr(layer, 'self_attn'):
        attn = layer.self_attn

        # Q, K, V, O projections
        if hasattr(attn, 'q_proj'):
            q_shape = attn.q_proj.weight.shape
            stats['attn_q_proj'] = f"{q_shape[0]} Ã— {q_shape[1]}"
            stats['attn_q_proj_params'] = q_shape[0] * q_shape[1]

        if hasattr(attn, 'k_proj'):
            k_shape = attn.k_proj.weight.shape
            stats['attn_k_proj'] = f"{k_shape[0]} Ã— {k_shape[1]}"
            stats['attn_k_proj_params'] = k_shape[0] * k_shape[1]

        if hasattr(attn, 'v_proj'):
            v_shape = attn.v_proj.weight.shape
            stats['attn_v_proj'] = f"{v_shape[0]} Ã— {v_shape[1]}"
            stats['attn_v_proj_params'] = v_shape[0] * v_shape[1]

        if hasattr(attn, 'o_proj'):
            o_shape = attn.o_proj.weight.shape
            stats['attn_o_proj'] = f"{o_shape[0]} Ã— {o_shape[1]}"
            stats['attn_o_proj_params'] = o_shape[0] * o_shape[1]

    # MLP æ¨¡å—
    if hasattr(layer, 'mlp'):
        mlp = layer.mlp

        if hasattr(mlp, 'gate_proj'):
            gate_shape = mlp.gate_proj.weight.shape
            stats['mlp_gate_proj'] = f"{gate_shape[0]} Ã— {gate_shape[1]}"
            stats['mlp_gate_proj_params'] = gate_shape[0] * gate_shape[1]

        if hasattr(mlp, 'up_proj'):
            up_shape = mlp.up_proj.weight.shape
            stats['mlp_up_proj'] = f"{up_shape[0]} Ã— {up_shape[1]}"
            stats['mlp_up_proj_params'] = up_shape[0] * up_shape[1]

        if hasattr(mlp, 'down_proj'):
            down_shape = mlp.down_proj.weight.shape
            stats['mlp_down_proj'] = f"{down_shape[0]} Ã— {down_shape[1]}"
            stats['mlp_down_proj_params'] = down_shape[0] * down_shape[1]

    return stats


def compare_models(original_model, pruned_model):
    """å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„æ¯ä¸€å±‚"""
    print("\n" + "="*100)
    print("å¼€å§‹é€å±‚åˆ†æ...")
    print("="*100)

    # è·å–å±‚æ•°
    original_layers = original_model.model.layers
    pruned_layers = pruned_model.model.layers

    num_layers = len(original_layers)
    print(f"\næ¨¡å‹æ€»å±‚æ•°: {num_layers}")

    # æ”¶é›†æ‰€æœ‰å±‚çš„ç»Ÿè®¡ä¿¡æ¯
    comparison_data = []

    for i in range(num_layers):
        print(f"\nåˆ†æç¬¬ {i} å±‚...")

        # åˆ†æåŸå§‹å±‚
        orig_stats = analyze_layer(original_layers[i], i, "original")

        # åˆ†æå‰ªæåçš„å±‚
        pruned_stats = analyze_layer(pruned_layers[i], i, "pruned")

        # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        layer_comparison = {
            'Layer': i,
        }

        # å¯¹æ¯”æ¯ä¸ªæ¨¡å—
        modules = ['attn_q_proj', 'attn_k_proj', 'attn_v_proj', 'attn_o_proj',
                  'mlp_gate_proj', 'mlp_up_proj', 'mlp_down_proj']

        total_orig_params = 0
        total_pruned_params = 0

        for module in modules:
            if module in orig_stats and module in pruned_stats:
                # ç»´åº¦ä¿¡æ¯
                layer_comparison[f'{module}_original'] = orig_stats[module]
                layer_comparison[f'{module}_pruned'] = pruned_stats[module]

                # å‚æ•°æ•°é‡
                orig_params = orig_stats.get(f'{module}_params', 0)
                pruned_params = pruned_stats.get(f'{module}_params', 0)

                total_orig_params += orig_params
                total_pruned_params += pruned_params

                # è®¡ç®—å‰ªæåº¦å’Œç¨€ç–åº¦
                if orig_params > 0:
                    retention_rate = pruned_params / orig_params
                    sparsity = 1 - retention_rate
                    layer_comparison[f'{module}_retention'] = f"{retention_rate:.4f}"
                    layer_comparison[f'{module}_sparsity'] = f"{sparsity:.4f}"

        # è®¡ç®—æ•´å±‚çš„å‰ªæåº¦å’Œç¨€ç–åº¦
        if total_orig_params > 0:
            layer_retention = total_pruned_params / total_orig_params
            layer_sparsity = 1 - layer_retention

            layer_comparison['total_original_params'] = total_orig_params
            layer_comparison['total_pruned_params'] = total_pruned_params
            layer_comparison['layer_retention_rate'] = f"{layer_retention:.4f}"
            layer_comparison['layer_sparsity'] = f"{layer_sparsity:.4f}"

        comparison_data.append(layer_comparison)

    return comparison_data


def print_summary_table(comparison_data):
    """æ‰“å°æ±‡æ€»è¡¨æ ¼"""
    print("\n" + "="*100)
    print("æ¯å±‚æ±‡æ€»ç»Ÿè®¡")
    print("="*100)

    # åˆ›å»ºæ±‡æ€»è¡¨æ ¼
    summary = []
    for data in comparison_data:
        summary.append({
            'å±‚ç¼–å·': data['Layer'],
            'åŸå§‹å‚æ•°é‡': f"{data['total_original_params']:,}",
            'å‰ªæåå‚æ•°é‡': f"{data['total_pruned_params']:,}",
            'ä¿ç•™ç‡': data['layer_retention_rate'],
            'ç¨€ç–åº¦': data['layer_sparsity'],
        })

    df = pd.DataFrame(summary)
    print("\n" + df.to_string(index=False))

    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    total_orig = sum(d['total_original_params'] for d in comparison_data)
    total_pruned = sum(d['total_pruned_params'] for d in comparison_data)
    overall_retention = total_pruned / total_orig if total_orig > 0 else 0
    overall_sparsity = 1 - overall_retention

    print("\n" + "="*100)
    print("å…¨å±€ç»Ÿè®¡")
    print("="*100)
    print(f"åŸå§‹æ¨¡å‹æ€»å‚æ•°é‡: {total_orig:,}")
    print(f"å‰ªæåæ¨¡å‹æ€»å‚æ•°é‡: {total_pruned:,}")
    print(f"å‚æ•°å‡å°‘é‡: {total_orig - total_pruned:,}")
    print(f"æ•´ä½“ä¿ç•™ç‡: {overall_retention:.4f} ({overall_retention*100:.2f}%)")
    print(f"æ•´ä½“ç¨€ç–åº¦: {overall_sparsity:.4f} ({overall_sparsity*100:.2f}%)")


def print_detailed_module_analysis(comparison_data):
    """æ‰“å°è¯¦ç»†çš„æ¨¡å—åˆ†æ"""
    print("\n" + "="*100)
    print("è¯¦ç»†æ¨¡å—åˆ†æ")
    print("="*100)

    modules = ['attn_q_proj', 'attn_k_proj', 'attn_v_proj', 'attn_o_proj',
              'mlp_gate_proj', 'mlp_up_proj', 'mlp_down_proj']

    module_names = {
        'attn_q_proj': 'Attention Q Projection',
        'attn_k_proj': 'Attention K Projection',
        'attn_v_proj': 'Attention V Projection',
        'attn_o_proj': 'Attention O Projection',
        'mlp_gate_proj': 'MLP Gate Projection',
        'mlp_up_proj': 'MLP Up Projection',
        'mlp_down_proj': 'MLP Down Projection',
    }

    for module in modules:
        print(f"\n{'â”€'*100}")
        print(f"ğŸ“Š {module_names[module]}")
        print(f"{'â”€'*100}")

        module_data = []
        for data in comparison_data:
            if f'{module}_original' in data:
                module_data.append({
                    'å±‚': data['Layer'],
                    'åŸå§‹ç»´åº¦': data.get(f'{module}_original', 'N/A'),
                    'å‰ªæåç»´åº¦': data.get(f'{module}_pruned', 'N/A'),
                    'ä¿ç•™ç‡': data.get(f'{module}_retention', 'N/A'),
                    'ç¨€ç–åº¦': data.get(f'{module}_sparsity', 'N/A'),
                })

        if module_data:
            df = pd.DataFrame(module_data)
            print(df.to_string(index=False))

            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å±‚éƒ½ä¸€æ ·
            retention_rates = [d['ä¿ç•™ç‡'] for d in module_data if d['ä¿ç•™ç‡'] != 'N/A']
            if retention_rates:
                unique_rates = set(retention_rates)
                if len(unique_rates) == 1:
                    print(f"\nâœ… æ‰€æœ‰å±‚çš„ {module_names[module]} å‰ªæåº¦ä¸€è‡´: {retention_rates[0]}")
                else:
                    print(f"\nâš ï¸  ä¸åŒå±‚çš„ {module_names[module]} å‰ªæåº¦ä¸åŒ")
                    print(f"   æœ€å°ä¿ç•™ç‡: {min(retention_rates)}")
                    print(f"   æœ€å¤§ä¿ç•™ç‡: {max(retention_rates)}")


def save_to_csv(comparison_data, output_file):
    """ä¿å­˜åˆ†æç»“æœåˆ°CSVæ–‡ä»¶"""
    print(f"\nä¿å­˜è¯¦ç»†åˆ†æç»“æœåˆ°: {output_file}")

    # å±•å¼€æ•°æ®
    rows = []
    for data in comparison_data:
        layer_idx = data['Layer']

        modules = ['attn_q_proj', 'attn_k_proj', 'attn_v_proj', 'attn_o_proj',
                  'mlp_gate_proj', 'mlp_up_proj', 'mlp_down_proj']

        for module in modules:
            if f'{module}_original' in data:
                rows.append({
                    'å±‚ç¼–å·': layer_idx,
                    'æ¨¡å—åç§°': module,
                    'åŸå§‹ç»´åº¦': data.get(f'{module}_original', ''),
                    'å‰ªæåç»´åº¦': data.get(f'{module}_pruned', ''),
                    'ä¿ç•™ç‡': data.get(f'{module}_retention', ''),
                    'ç¨€ç–åº¦': data.get(f'{module}_sparsity', ''),
                })

    df = pd.DataFrame(rows)
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ… å·²ä¿å­˜ {len(rows)} æ¡è®°å½•åˆ° {output_file}")


def main():
    parser = argparse.ArgumentParser(description='åˆ†æåŸå§‹æ¨¡å‹å’Œå‰ªæåæ¨¡å‹çš„å·®å¼‚')
    parser.add_argument('--original_model', type=str, required=True,
                       help='åŸå§‹æ¨¡å‹è·¯å¾„ (HuggingFace æ¨¡å‹ç›®å½•)')
    parser.add_argument('--pruned_model', type=str, required=True,
                       help='å‰ªæåæ¨¡å‹è·¯å¾„ (.bin æ–‡ä»¶)')
    parser.add_argument('--output', type=str, default='pruning_analysis.csv',
                       help='è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ (é»˜è®¤: pruning_analysis.csv)')
    parser.add_argument('--layers', type=str, default=None,
                       help='æŒ‡å®šè¦åˆ†æçš„å±‚ï¼Œä¾‹å¦‚ "0,1,2" æˆ– "0-5" (é»˜è®¤: æ‰€æœ‰å±‚)')

    args = parser.parse_args()

    print("="*100)
    print("å‰ªæåˆ†æå·¥å…·")
    print("="*100)
    print(f"åŸå§‹æ¨¡å‹: {args.original_model}")
    print(f"å‰ªææ¨¡å‹: {args.pruned_model}")
    print("="*100)

    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½åŸå§‹æ¨¡å‹...")
    original_model = load_model(args.original_model, is_pruned=False)

    print("\nåŠ è½½å‰ªæåæ¨¡å‹...")
    pruned_model = load_model(args.pruned_model, is_pruned=True)

    # å¯¹æ¯”åˆ†æ
    comparison_data = compare_models(original_model, pruned_model)

    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print_summary_table(comparison_data)

    # æ‰“å°è¯¦ç»†æ¨¡å—åˆ†æ
    print_detailed_module_analysis(comparison_data)

    # ä¿å­˜åˆ°CSV
    save_to_csv(comparison_data, args.output)

    print("\n" + "="*100)
    print("åˆ†æå®Œæˆï¼")
    print("="*100)


if __name__ == "__main__":
    main()
